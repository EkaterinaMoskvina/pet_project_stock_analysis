# Аналитическая Платформа для Прогнозирования Цен Акций

Этот pet-project представляет собой end-to-end MLOps платформу для сбора, обработки, анализа данных по акциям и прогнозирования их стоимости на неделю вперед. Проект построен на современном стеке технологий, который часто используется в production-окружениях.

## Цель проекта

Создать полностью автоматизированный пайплайн, который:
1.  **Собирает** исторические данные по котировкам акций из публичного API.
2.  **Хранит** сырые данные в Data Lake (S3) и обработанные данные в аналитическом хранилище (ClickHouse).
3.  **Трансформирует** и подготавливает данные для обучения моделей машинного обучения.
4.  **Обучает** ML-модели для прогнозирования цен и сохраняет их артефакты.
5.  **Делает прогнозы** на основе свежих данных и сохраняет результаты.
6.  **Визуализирует** исторические данные и прогнозы на дашбордах.

## Технологический стек

| Инструмент | Категория | Роль в проекте |
| :--- | :--- | :--- |
| **Python** | Язык | Основной язык для написания скриптов и логики. |
| **Docker** | Контейнеризация | Изолированное развертывание всех сервисов локально. |
| **Airflow** | Оркестратор | Управление и запуск всех задач по расписанию. |
| **`dlt`** | Загрузчик (EL) | Загрузка данных из API в Data Lake. |
| **S3 (MinIO)** | Data Lake | Хранилище для сырых данных, моделей и других артефактов. |
| **ClickHouse** | DWH | Сверхбыстрая аналитическая база данных для витрин. |
| **dbt** | Трансформер (T) | Преобразование данных внутри ClickHouse (EL**T**-подход). |
| **DuckDB** | Ad-hoc аналитика | Быстрый анализ данных напрямую в S3. |
| **MLflow** | MLOps | Отслеживание экспериментов, версионирование моделей. |
| **Scikit-learn** | Машинное обучение | Библиотека для создания ML моделей. |
| **Apache Superset** | BI / Визуализация | Создание интерактивных дашбордов. |
| **Metastore** | Каталог данных | Хранение метаданных о схемах данных в S3. |

## 🏗️ Архитектура и поток данных (Data Flow)

Процесс разделен на четыре основных этапа, которые оркестрируются с помощью Airflow.

```mermaid
graph TD
    subgraph "Этап 1: Сбор данных (Ingestion)"
        A[API Источник] -->|1. Запрос данных| B(Python + dlt);
        B -->|2. Загрузка сырых данных| C[S3 Data Lake];
    end

    subgraph "Этап 2: Трансформация (ELT)"
        C -->|3. Чтение из S3| D{dbt};
        D -->|4. Трансформация и запись| E[(ClickHouse DWH)];
    end

    subgraph "Этап 3: Машинное обучение (ML)"
        E -->|5. Данные для обучения| F[ML Model Training];
        F -->|6. Логирование эксперимента| G[MLflow];
        F -->|7. Сохранение модели| C;
        E -->|8. Свежие данные| H[ML Inference];
        C -->|Загрузка модели| H;
        H -->|9. Запись прогноза| E;
    end

    subgraph "Эта- 4: Визуализация (Analytics)"
        E -->|10. Данные для отчетов| I(BI-инструмент / Superset);
        I --> J[Дашборды];
    end

    subgraph "Оркестрация"
        K(Airflow) -.-> B;
        K -.-> D;
        K -.-> F;
        K -.-> H;
    end
